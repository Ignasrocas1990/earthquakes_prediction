{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c20b40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import tree\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score \n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9512bcc7",
   "metadata": {},
   "source": [
    "## Teams Communication log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7291272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TeamsLogUrl=(\"https://www.dropbox.com/s/tk9q2z34e8nyiqq/Teams%20Communication%20log.txt?dl=1\")\n",
    "file = urllib.request.urlopen(TeamsLogUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d16ba21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for line in file:\n",
    "    decoded_line = line.decode(\"utf-8\")\n",
    "    print(decoded_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9346554",
   "metadata": {},
   "source": [
    "# Section 1\n",
    "\n",
    "Authour : Ignas Rocas, \n",
    "\n",
    "Student Nr: C00135830,\n",
    "\n",
    "Purpose : CA1 Data Science ,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e286b4",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96049da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean data\n",
    "e_data = pd.read_csv(\"https://www.dropbox.com/s/ey2y94hyfclgl98/clean_data.csv?dl=1\")\n",
    "e_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b3ec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48b2a05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "e_data['Year'] = e_data['Year'].apply(int)\n",
    "e_data['Day'] = e_data['Day'].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c358e2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start = datetime(1965,1,1)\n",
    "current = datetime(e_data['Year'][0], e_data['Month'][0], e_data['Day'][0], 0, 0)\n",
    "s = int((current - start).total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb131fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = list()\n",
    "for i in range(len(e_data['Year'])):\n",
    "    current = datetime(e_data['Year'][i], e_data['Month'][i], e_data['Day'][i], 0, 0)\n",
    "    s = int((current - start).total_seconds())\n",
    "    dates.append(s)\n",
    "e_data['Date']=pd.Series(dates)\n",
    "e_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e503a86e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "e_data['DATE'] = pd.to_datetime(e_data[['Year', 'Month','Day']])\n",
    "e_data = e_data.drop(['Unnamed: 0','Month','Day','Year'],axis=1)\n",
    "e_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2570c089",
   "metadata": {},
   "source": [
    "# Corroletion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb71ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows that the correletion bettween features are too great for Linear and Multi-Linear Regression\n",
    "corrMatrix = e_data.corr()\n",
    "sn.heatmap(corrMatrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2995169c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = e_data['Latitude'].values\n",
    "X = e_data['Longitude'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee83cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just to see how the points look and clearly n\n",
    "plt.scatter(X, y, color='black')\n",
    "plt.title('all the earthquakes')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f042d65",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b4d2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate data & split data\n",
    "X = e_data[['Longitude', 'Latitude', 'Magnitude','Density']]\n",
    "y = e_data['Date']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28491ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#user random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest = RandomForestRegressor(random_state = 42)\n",
    "forest.fit(X_train, y_train)\n",
    "pred = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5e6a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest evaluation\n",
    "print(\"Score : \", forest.score(X_test,y_test))\n",
    "print(\"Mean squared error : \", mean_squared_error(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff836609",
   "metadata": {},
   "source": [
    "# DBSCAN Clustering (knns,decision trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf00af1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = e_data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6828f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#https://medium.com/@tarammullin/dbscan-parameter-estimation-ff8330e3a3bd\n",
    "#followed article above which parameters to pick for DBSCAN\n",
    "\n",
    "#used The k-nearest neighbors to pick the best eps for DBSCAN\n",
    "neighbors = NearestNeighbors(n_neighbors=4)#neigbors set to min_samples\n",
    "neighbors_fit = neighbors.fit(df[['Latitude','Longitude']])\n",
    "distances, indices = neighbors_fit.kneighbors(df[['Latitude','Longitude']])\n",
    "distances = np.sort(distances, axis=0)\n",
    "distances = distances[:,1]\n",
    "plt.figure(figsize=(30,30))\n",
    "plt.plot(distances)\n",
    "# show that best eps is close to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948c2cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#user DBSCAN and save its labels to dataframe\n",
    "dbscan=DBSCAN(eps=1.6,min_samples=4)\n",
    "dbscan.fit_predict(df[['Longitude','Latitude']])\n",
    "df['Cluster']=dbscan.labels_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d04e066",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot all the data\n",
    "def plot(df):\n",
    "    plt.scatter(df['Longitude'],df['Latitude'],c=df['Cluster'],cmap=\"viridis_r\")\n",
    "    plt.title('DBSCAN Clustering',fontsize=20)\n",
    "    plt.xlabel('Longitude',fontsize=14)\n",
    "    plt.ylabel('Latitude',fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc937f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0912e969",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get unique clusters and remove outliners\n",
    "#(-1 lable,and any clusters with 1 element) - display the results\n",
    "\n",
    "clusters = df['Cluster'].value_counts().index\n",
    "clusters = list(clusters)\n",
    "clusters.sort()\n",
    "removeList = [-1,126]#126 has the same date in same cluster/ same location\n",
    "temp =  [i for i in clusters if len(df[df.Cluster==i])<4]\n",
    "removeList.extend(temp)\n",
    "\n",
    "for i in removeList:\n",
    "    if i in clusters:\n",
    "        clusters.remove(i)\n",
    "    \n",
    "    \n",
    "df = df[df['Cluster'].isin(clusters) == True]\n",
    "plt.figure(figsize=(20,10))\n",
    "plot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302b92bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f884378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get one cluster and display it\n",
    "two = df[df.Cluster == 2]\n",
    "plt.scatter(two['Longitude'],two['Latitude'],c=two['Cluster'],cmap=\"viridis_r\")\n",
    "plt.legend(two['Cluster'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84574a65",
   "metadata": {},
   "source": [
    "NOTES: So we get all the averages time in between the earthquakes for each of the cluster. Then we use Decetion trees to predict incomping new data (users location(longatude/latidue) => y(Cluster)) So we can derive the next earthquake data,from (previous know erthquake date)+(predicted average inbetween for that Cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4e9d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Cluster == 2].Cluster.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388d5f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate for each cluster the averate time inbetween the earthquakes \n",
    "avgCluDict = {}\n",
    "for n in clusters:# --------all the unique cluster\n",
    "    curCluster = df[df.Cluster == n]#-------------get each cluster\n",
    "    curNumber = curCluster.Cluster.iloc[0] # get cluster number\n",
    "    total=0\n",
    "    count=0\n",
    "    for x in range(len(curCluster)):\n",
    "        a = curCluster['DATE'].iloc[x]\n",
    "        x+=1\n",
    "        if(x<len(curCluster)):\n",
    "            b = curCluster['DATE'].iloc[x]\n",
    "            total+= (b-a).total_seconds()\n",
    "            count +=1\n",
    "        x-=1\n",
    "    if(total > 0 and count > 0):  \n",
    "        #avgCluster.append(int(total/count))\n",
    "        avgCluDict[curNumber]=int(total/count)\n",
    "        \n",
    "len(avgCluDict)#need create dictionary from cluster number and average\n",
    "\n",
    "#append the new averages to dataframe\n",
    "tempList = []\n",
    "for row in df.iterrows():\n",
    "    cluster = row[1]['Cluster']\n",
    "    if(cluster in avgCluDict.keys()):\n",
    "        tempList.append(avgCluDict[cluster])\n",
    "df['DateAvg']=tempList\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56865d8d",
   "metadata": {},
   "source": [
    "Use decision trees to predict cluster, when new data (latidude and logitude) comes in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcd011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X = df[['Latitude','Longitude']]\n",
    "y = df['Cluster']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84fae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a regressor object\n",
    "dtr = DecisionTreeRegressor(random_state = 0) \n",
    "dtr.fit(X_train, y_train)\n",
    "dtr.score(X_test, y_test)\n",
    "y_pred=dtr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf05c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get first prediction (cluster) & get acompaning average days\n",
    "testCluster=y_pred[2]\n",
    "sec = df[df.Cluster == int(testCluster)]['DateAvg'].iloc[0]\n",
    "\n",
    "sec = timedelta(seconds=int(sec))\n",
    "print(sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac17432",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get last date of in that cluster & change to next earthquoke date\n",
    "lastKnowDate=df[df.Cluster==int(testCluster)]['DATE'].iloc[-1] # 2016-12-20\n",
    "new_datetime = lastKnowDate + sec\n",
    "print(\"cluster : \",testCluster,\"=>\",new_datetime) # next earthquoke in the cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e68ce41",
   "metadata": {},
   "outputs": [],
   "source": [
    "clu = df[df.Cluster==testCluster]\n",
    "plot(clu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8a84cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
